\section{Introduction}
Almost all science is about identifying causal relations and the laws or regularities that govern them. Interventions or randomized experiments are a common technique to find causal relationships, but they are in many cases too expensive, time-consuming, or even impossible to do. Therefore, researchers have drawn much attention by revealing causal information by analyzing purely observational data, a process known as causal discovery \cite{spirtes2000causation}. \newline

In automated analysis, causal discovery is a prominent approach to extracting contextual information. It removes spurious correlations from the results, allowing operators to concentrate on crucial details. One practical and natural method for efficient analysis is to leverage domain knowledge on a target network. In manual operation, network operators empirically select valuable information from various data sources based on their domain knowledge. This information selection is not always accurate, but it effectively improves troubleshooting. \newline

Software systems are becoming increasingly massive and complex, containing hundreds of services distributed across thousands of or even hundreds of thousands of servers and supporting many concurrent users. One particular challenge for large-scale software systems is anomaly diagnosis. That is, when problems occur, how to quickly diagnose problems, and how administrators can quickly identify root causes. Logs are a straightforward and common source of information for problem diagnosis \cite{aussel2018improving,du2017deeplog,otomo2019latent}. Typically, administrators manually check log files and search for problem-related log lines. However, in today’s large-scale systems, logs can be overwhelmingly large. For instance, in some large-scale systems that provide global services, daily log data could reach tens of terabytes. On the other hand, problems of today’s system’s architectures can be cross-component and cross-service; for example, it is hard to get root causes based on particular “error” logs. As a result, identifying problems by hand can be time-consuming and error-prone. Understanding the dependencies among different components of a large-scale distributed system is extremely important for problem diagnosis.

In this paper, I aim to provide a comprehensive review of learning causality from massive log data. Below, I present an outline of the topics covered in this paper. First, in Section \hyperref[sec:2]{2}, I introduce a general approach structure that I have identified in my literature study on what methods exist. Section \hyperref[sec:3]{3} focuses on the methods developed for the problem of efficient log templates generation. In Section \hyperref[sec:4]{4}, the widely used straightforward methods for event time-series creation are discussed. Afterward, in Section \hyperref[sec:5]{5}, I discuss the preliminaries of learning causality from data for causal discovery. I will start with the constraint-based, score-based as well as functional-based methods. At the end of this section, I introduce one of the most known algorithms to deal with causal, temporal data — the Granger causality. Finally, Section \hyperref[sec:6]{6} gives a brief conclusion.

