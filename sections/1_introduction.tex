\section{Introduction}
Almost all science is about identifying causal relations and the laws or regularities that govern them. Interventions or randomized experiments are a common technique to find causal relationships, but they are often too expensive, time-consuming, or even impossible to do. Therefore, researchers have drawn much attention by revealing causal information by analyzing purely observational data, a process known as causal discovery \cite{spirtes2000causation}. \newline

In automated analysis, causal discovery is a prominent approach to extracting contextual information. It removes spurious correlations from the results, allowing operators to concentrate on crucial details. One practical and natural method for efficient analysis is to leverage domain knowledge on a target network. Network operators empirically select valuable information from various data sources based on their domain knowledge in manual operation. This information selection is not always accurate, but it effectively improves troubleshooting. \newline

Software systems are becoming increasingly massive and complex, containing hundreds of services distributed across thousands or even hundreds of thousands of servers and supporting many concurrent users. One particular challenge for large-scale software systems is anomaly diagnosis. When problems occur, how can they be quickly diagnosed, and how can administrators rapidly identify root causes? Logs are a straightforward and common source of information for problem diagnosis \cite{aussel2018improving,du2017deeplog,otomo2019latent}. Typically, administrators manually check log files and search for problem-related log lines. However, in today’s large-scale systems, logs can be overwhelmingly large. For instance, daily log data could reach tens of terabytes in some large-scale systems that provide global services. On the other hand, problems of today’s system’s architectures can be cross-component and cross-service; for example, it is hard to get root causes based on particular “error” logs. As a result, identifying problems by hand can be time-consuming and error-prone. Understanding the dependencies among different components of a large-scale distributed system is extremely important for problem diagnosis.

This paper aims to provide a comprehensive review of learning causality from massive log data. Below, I present an outline of the topics covered in this paper. First, in Section \hyperref[sec:2]{2}, I introduce a general approach structure that I have identified in my literature study on what methods exist. Section \hyperref[sec:3]{3} focuses on the methods developed for the problem of efficient log template generation. Section \hyperref[sec:4]{4} discusses the widely used straightforward methods for event time-series creation. Afterward, in Section \hyperref[sec:5]{5}, I discuss the preliminaries of learning causality from data for causal discovery. I will start with the constraint-based, score-based, and functional-based methods. At the end of this section, I introduce one of the most known algorithms to deal with causal, temporal data — the Granger causality. Finally, Section \hyperref[sec:6]{6} gives a brief conclusion.

